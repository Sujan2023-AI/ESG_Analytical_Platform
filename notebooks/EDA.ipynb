{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy.stats.mstats import winsorize\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed esg_raw_data_on_corporations_myu_5.csv: E(396333), S(51959), G(74546)\n",
      "Processed esg_raw_data_on_corporations_myu_2.csv: E(894601), S(196542), G(231277)\n",
      "Processed esg_raw_data_on_corporations_1.csv: E(1269834), S(768008), G(726410)\n",
      "Processed esg_raw_data_on_corporations_myu_4.csv: E(624877), S(74975), G(112890)\n",
      "Processed esg_raw_data_on_corporations_myu_3.csv: E(767791), S(100980), G(155926)\n",
      "Processed esg_raw_data_on_corporations_7.csv: E(50502), S(14844), G(21025)\n",
      "Processed esg_raw_data_on_corporations_6.csv: E(190863), S(25985), G(40755)\n",
      "CSV files saved successfully in the processed folder:\n",
      "- Environmental Data: 4194801 rows\n",
      "- Social Data: 1233293 rows\n",
      "- Governance Data: 1362829 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the directory where raw CSV files are stored\n",
    "raw_folder_path = '/Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/raw/Raw data ESG data 2025Feb'  # Update this if needed\n",
    "\n",
    "# Define the directory where processed files should be saved\n",
    "processed_folder_path = \"/Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/processed\"\n",
    "\n",
    "# Ensure the processed folder exists\n",
    "os.makedirs(processed_folder_path, exist_ok=True)\n",
    "\n",
    "# List of ESG raw data files\n",
    "csv_files = [\n",
    "    \"esg_raw_data_on_corporations_myu_5.csv\",\n",
    "    \"esg_raw_data_on_corporations_myu_2.csv\",\n",
    "    \"esg_raw_data_on_corporations_1.csv\",\n",
    "    \"esg_raw_data_on_corporations_myu_4.csv\",\n",
    "    \"esg_raw_data_on_corporations_myu_3.csv\",\n",
    "    \"esg_raw_data_on_corporations_7.csv\",\n",
    "    \"esg_raw_data_on_corporations_6.csv\"\n",
    "]\n",
    "\n",
    "# Initialize empty lists for E, S, and G dataframes\n",
    "e_dataframes = []\n",
    "s_dataframes = []\n",
    "g_dataframes = []\n",
    "\n",
    "# Loop through each file and read the data\n",
    "for filename in csv_files:\n",
    "    file_path = os.path.join(raw_folder_path, filename)\n",
    "\n",
    "    try:\n",
    "        # Read CSV file with correct delimiter\n",
    "        df = pd.read_csv(file_path, delimiter='|', encoding='utf-8')\n",
    "\n",
    "        # Ensure 'pillar' column exists before filtering\n",
    "        if 'pillar' in df.columns:\n",
    "            e_dataframes.append(df[df['pillar'] == 'E'])\n",
    "            s_dataframes.append(df[df['pillar'] == 'S'])\n",
    "            g_dataframes.append(df[df['pillar'] == 'G'])\n",
    "\n",
    "            print(f\"Processed {filename}: E({len(e_dataframes[-1])}), S({len(s_dataframes[-1])}), G({len(g_dataframes[-1])})\")\n",
    "        else:\n",
    "            print(f\"Skipping {filename} - 'pillar' column missing.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "# Combine all files into one per category\n",
    "df_e = pd.concat(e_dataframes, ignore_index=True)\n",
    "df_s = pd.concat(s_dataframes, ignore_index=True)\n",
    "df_g = pd.concat(g_dataframes, ignore_index=True)\n",
    "\n",
    "# Save the new CSV files in the processed directory\n",
    "df_e.to_csv(os.path.join(processed_folder_path, \"esg_environmental_data.csv\"), index=False, sep='|')\n",
    "df_s.to_csv(os.path.join(processed_folder_path, \"esg_social_data.csv\"), index=False, sep='|')\n",
    "df_g.to_csv(os.path.join(processed_folder_path, \"esg_governance_data.csv\"), index=False, sep='|')\n",
    "\n",
    "print(\"CSV files saved successfully in the processed folder:\")\n",
    "print(f\"- Environmental Data: {len(df_e)} rows\")\n",
    "print(f\"- Social Data: {len(df_s)} rows\")\n",
    "print(f\"- Governance Data: {len(df_g)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting complete! Files saved successfully with Industry information (matched by perm_id) in the processed folder:\n",
      "- Environmental Risk: 3196816 rows\n",
      "- Environmental Opportunity: 752505 rows\n",
      "- Social Risk: 738425 rows\n",
      "- Social Opportunity: 494868 rows\n",
      "- Governance Risk: 257120 rows\n",
      "- Governance Opportunity: 499455 rows\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "processed_folder_path = \"/Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/processed\"\n",
    "metric_summary_path = \"/Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/raw/metric_summary.csv\"\n",
    "industry_file_path = \"/Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/raw/industry.csv\"  # Industry file\n",
    "\n",
    "# Load the Metric Summary file\n",
    "metric_summary = pd.read_csv(metric_summary_path)\n",
    "\n",
    "# Ensure the required columns exist in the metric summary\n",
    "if 'metric_name' not in metric_summary.columns or 'category' not in metric_summary.columns:\n",
    "    raise ValueError(\"Metric Summary file must contain 'metric_name' and 'category' columns.\")\n",
    "\n",
    "# Load the Industry file\n",
    "industry_data = pd.read_csv(industry_file_path)\n",
    "\n",
    "# Rename columns for consistency\n",
    "industry_data.rename(columns={'Industry': 'industry'}, inplace=True)\n",
    "\n",
    "# Ensure 'perm_id' and 'industry' columns exist after renaming\n",
    "if 'perm_id' not in industry_data.columns or 'industry' not in industry_data.columns:\n",
    "    raise ValueError(\"Industry file must contain 'perm_id' and 'industry' columns.\")\n",
    "\n",
    "# Load processed ESG files\n",
    "e_file = os.path.join(processed_folder_path, \"esg_environmental_data.csv\")\n",
    "s_file = os.path.join(processed_folder_path, \"esg_social_data.csv\")\n",
    "g_file = os.path.join(processed_folder_path, \"esg_governance_data.csv\")\n",
    "\n",
    "df_e = pd.read_csv(e_file, delimiter='|', encoding='utf-8')\n",
    "df_s = pd.read_csv(s_file, delimiter='|', encoding='utf-8')\n",
    "df_g = pd.read_csv(g_file, delimiter='|', encoding='utf-8')\n",
    "\n",
    "# Merge industry data into ESG datasets using 'perm_id'\n",
    "df_e = df_e.merge(industry_data[['perm_id', 'industry']], on='perm_id', how='left')\n",
    "df_s = df_s.merge(industry_data[['perm_id', 'industry']], on='perm_id', how='left')\n",
    "df_g = df_g.merge(industry_data[['perm_id', 'industry']], on='perm_id', how='left')\n",
    "\n",
    "# Split the datasets using the Metric Summary\n",
    "\n",
    "# Environmental (E)\n",
    "e_risk_metrics = metric_summary[metric_summary['category'] == 'Environmental Risk']['metric_name'].tolist()\n",
    "e_opportunity_metrics = metric_summary[metric_summary['category'] == 'Environmental Opportunity']['metric_name'].tolist()\n",
    "\n",
    "df_e_risk = df_e[df_e['metric_name'].isin(e_risk_metrics)]\n",
    "df_e_opportunity = df_e[df_e['metric_name'].isin(e_opportunity_metrics)]\n",
    "\n",
    "# Social (S)\n",
    "s_risk_metrics = metric_summary[metric_summary['category'] == 'Social Risk']['metric_name'].tolist()\n",
    "s_opportunity_metrics = metric_summary[metric_summary['category'] == 'Social Opportunity']['metric_name'].tolist()\n",
    "\n",
    "df_s_risk = df_s[df_s['metric_name'].isin(s_risk_metrics)]\n",
    "df_s_opportunity = df_s[df_s['metric_name'].isin(s_opportunity_metrics)]\n",
    "\n",
    "# Governance (G)\n",
    "g_risk_metrics = metric_summary[metric_summary['category'] == 'Governance Risk']['metric_name'].tolist()\n",
    "g_opportunity_metrics = metric_summary[metric_summary['category'] == 'Governance Opportunity']['metric_name'].tolist()\n",
    "\n",
    "df_g_risk = df_g[df_g['metric_name'].isin(g_risk_metrics)]\n",
    "df_g_opportunity = df_g[df_g['metric_name'].isin(g_opportunity_metrics)]\n",
    "\n",
    "# Save the final split files in the processed directory\n",
    "df_e_risk.to_csv(os.path.join(processed_folder_path, \"esg_environmental_risk.csv\"), index=False, sep='|')\n",
    "df_e_opportunity.to_csv(os.path.join(processed_folder_path, \"esg_environmental_opportunity.csv\"), index=False, sep='|')\n",
    "\n",
    "df_s_risk.to_csv(os.path.join(processed_folder_path, \"esg_social_risk.csv\"), index=False, sep='|')\n",
    "df_s_opportunity.to_csv(os.path.join(processed_folder_path, \"esg_social_opportunity.csv\"), index=False, sep='|')\n",
    "\n",
    "df_g_risk.to_csv(os.path.join(processed_folder_path, \"esg_governance_risk.csv\"), index=False, sep='|')\n",
    "df_g_opportunity.to_csv(os.path.join(processed_folder_path, \"esg_governance_opportunity.csv\"), index=False, sep='|')\n",
    "\n",
    "# Print results\n",
    "print(\"Splitting complete! Files saved successfully with Industry information (matched by perm_id) in the processed folder:\")\n",
    "print(f\"- Environmental Risk: {len(df_e_risk)} rows\")\n",
    "print(f\"- Environmental Opportunity: {len(df_e_opportunity)} rows\")\n",
    "print(f\"- Social Risk: {len(df_s_risk)} rows\")\n",
    "print(f\"- Social Opportunity: {len(df_s_opportunity)} rows\")\n",
    "print(f\"- Governance Risk: {len(df_g_risk)} rows\")\n",
    "print(f\"- Governance Opportunity: {len(df_g_opportunity)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned file saved: /Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/processed/esg_environmental_risk_cleaned.csv (Rows: 3196816)\n",
      "✅ Cleaned file saved: /Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/processed/esg_environmental_opportunity_cleaned.csv (Rows: 752505)\n",
      "✅ Cleaned file saved: /Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/processed/esg_social_risk_cleaned.csv (Rows: 738425)\n",
      "✅ Cleaned file saved: /Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/processed/esg_social_opportunity_cleaned.csv (Rows: 494868)\n",
      "✅ Cleaned file saved: /Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/processed/esg_governance_risk_cleaned.csv (Rows: 257120)\n",
      "✅ Cleaned file saved: /Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/processed/esg_governance_opportunity_cleaned.csv (Rows: 499455)\n",
      "\n",
      "🎯 Cleaning process complete! All cleaned files are now stored in the processed folder.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "processed_folder_path = \"/Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/processed\"\n",
    "\n",
    "# List of files to clean\n",
    "files_to_clean = [\n",
    "    \"esg_environmental_risk.csv\",\n",
    "    \"esg_environmental_opportunity.csv\",\n",
    "    \"esg_social_risk.csv\",\n",
    "    \"esg_social_opportunity.csv\",\n",
    "    \"esg_governance_risk.csv\",\n",
    "    \"esg_governance_opportunity.csv\"\n",
    "]\n",
    "\n",
    "# Process each file\n",
    "for filename in files_to_clean:\n",
    "    file_path = os.path.join(processed_folder_path, filename)\n",
    "\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path, delimiter='|', encoding='utf-8')\n",
    "\n",
    "    # Extract year from 'metric_year' column\n",
    "    if 'metric_year' in df.columns:\n",
    "        df['year'] = pd.to_datetime(df['metric_year'], errors='coerce').dt.year  # Extract year\n",
    "        df.drop(columns=['metric_year'], inplace=True)  # Remove original column after extraction\n",
    "\n",
    "    # Drop columns that are completely empty (100% missing)\n",
    "    df_cleaned = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Save the cleaned file with `_cleaned` suffix\n",
    "    cleaned_file_path = os.path.join(processed_folder_path, filename.replace('.csv', '_cleaned.csv'))\n",
    "    df_cleaned.to_csv(cleaned_file_path, index=False, sep='|')\n",
    "\n",
    "    print(f\"✅ Cleaned file saved: {cleaned_file_path} (Rows: {len(df_cleaned)})\")\n",
    "\n",
    "print(\"\\n🎯 Cleaning process complete! All cleaned files are now stored in the processed folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      company_name     perm_id data_type  disclosure  \\\n",
      "0  Landsbankinn hf  5000632996       int  CALCULATED   \n",
      "1  Landsbankinn hf  5000632996       int  CALCULATED   \n",
      "2  Landsbankinn hf  5000632996     float    REPORTED   \n",
      "3  Landsbankinn hf  5000632996       int  CALCULATED   \n",
      "4  Landsbankinn hf  5000632996     float   ESTIMATED   \n",
      "\n",
      "                                  metric_description  \\\n",
      "0  Does the company have a policy to improve its ...   \n",
      "1  Does the company develop products or technolog...   \n",
      "2  Total waste that is generated by the company a...   \n",
      "3  Does the company develop products and services...   \n",
      "4  Total energy consumed by a company within its ...   \n",
      "\n",
      "                     metric_name metric_unit  metric_value  \\\n",
      "0        POLICY_WATER_EFFICIENCY      Yes/No          0.00   \n",
      "1             WATER_TECHNOLOGIES      Yes/No          0.00   \n",
      "2                 WASTE_RECYCLED        Tons         86.17   \n",
      "3  SUSTAINABLE_BUILDING_PRODUCTS      Yes/No          0.00   \n",
      "4                 ENERGYUSETOTAL          GJ      15412.89   \n",
      "\n",
      "   nb_points_of_observations provider_name        reported_date pillar  \\\n",
      "0                        293    Clarity AI  2020-12-31 00:00:00      E   \n",
      "1                        293    Clarity AI  2021-12-31 00:00:00      E   \n",
      "2                        293    Clarity AI  2023-12-31 00:00:00      E   \n",
      "3                        293    Clarity AI  2019-12-31 00:00:00      E   \n",
      "4                        293    Clarity AI                  NaN      E   \n",
      "\n",
      "  headquarter_country                industry  year  \n",
      "0                 NaN  Software & IT Services  2020  \n",
      "1                 NaN  Software & IT Services  2021  \n",
      "2                 NaN  Software & IT Services  2023  \n",
      "3                 NaN  Software & IT Services  2019  \n",
      "4                 NaN  Software & IT Services  2017  \n"
     ]
    }
   ],
   "source": [
    "# Define file path\n",
    "file_path = \"/Users/sujanbharadwaj/Library/Mobile Documents/com~apple~CloudDocs/Documents/Ontology_PCA_Project/data/processed/esg_environmental_opportunity_cleaned.csv\"\n",
    "\n",
    "# Read the CSV file using the correct delimiter '|'\n",
    "df_env_oppr_cleaned = pd.read_csv(file_path, delimiter='|', encoding='utf-8')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df_env_oppr_cleaned.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
